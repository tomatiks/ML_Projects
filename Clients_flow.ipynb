{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Условие:\n",
    "\n",
    "В отделениях банка установлены терминалы электронной очереди. <br>\n",
    "Для обслуживания, клиент берет талон. Один талон – один клиент. <br>\n",
    "Талон имеет категорию и в зависимости от нее может быть обслужен либо у менеджера по обслуживанию (МО), либо у менеджера по <br> продажам (МП). <br>\n",
    "\n",
    "Какое обслуживание требуется определяет поле CURR_OPCAT_ID (категория талона). <br>\n",
    "Соответствие роли и категории талона указано в файле OPCAT_ID_HIST_mapping.xlsx <br>\n",
    "При этом, в разные года значение этого поля может меняться. <br>\n",
    "Файл opcat_hist.csv хранит историю изменений для значений поля CURR_OPCAT_ID. <br>\n",
    "\n",
    "Необходимо построить модель, прогнозирующую клиентопоток (сколько клиентов придет на обслуживание в каждый час) для каждого <br> отделения банка к каждому менеджеру. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split,TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelBinarizer,LabelEncoder,PolynomialFeatures\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LassoCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Считываем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tickets132 = pd.read_csv('tickets/tickets_2013_02.csv', sep=';',encoding ='utf8')\n",
    "tickets141 = pd.read_csv('tickets/tickets_2014_01.csv', sep=';',encoding ='utf8')\n",
    "tickets142 = pd.read_csv('tickets/tickets_2014_02.csv', sep=';',encoding ='utf8')\n",
    "tickets151 = pd.read_csv('tickets/tickets_2015_01.csv', sep=';',encoding ='utf8')\n",
    "tickets152 = pd.read_csv('tickets/tickets_2015_02.csv', sep=';',encoding ='utf8')\n",
    "opcat_hist=pd.read_csv('opcat_hist.csv', sep=';',encoding ='utf8')\n",
    "opcat_map=pd.read_csv('OPCAT_ID_HIST_mapping.csv', sep=';',encoding ='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tickets=tickets132.append([tickets141,tickets142,tickets151,tickets152])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразуем данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как я выяснил: <br>\n",
    "CURR_COUNTER - номер окошка в котором принимают клиента<br>\n",
    "USER_ID - id менеджера<br>\n",
    "TICKET_WAIT_TIME,TICKET_SERV_TIME - время ожидания и обслуживания<br>\n",
    "\n",
    "Эти параметры нам не нужны для определения кол-ва клиентов к каждому типу менеджеров<br>\n",
    "\n",
    "EVENT_TYPE_ID - id действия по билету <br>\n",
    "Для нашей задачи достаточно взять строчки с 'EVENT_TYPE_ID'==1 (получение билета), так как нам нужно именно понять сколько клиентов пришло в отделение в определенный час (а не их последующие действия)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tickets=tickets.drop(['CURR_COUNTER','USER_ID','TICKET_WAIT_TIME','TICKET_SERV_TIME'],axis=1)\n",
    "tickets=tickets[tickets['EVENT_TYPE_ID']==1].drop(['EVENT_TYPE_ID'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1593063 entries, 0 to 985002\n",
      "Data columns (total 4 columns):\n",
      "SUBBRANCH_ID     1593063 non-null int64\n",
      "CURR_OPCAT_ID    1593063 non-null int64\n",
      "EVENT_DTTM       1593063 non-null object\n",
      "TICKET_ID        1593063 non-null object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 60.8+ MB\n"
     ]
    }
   ],
   "source": [
    "tickets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таблице истории категорий переводим время в формат datetime (5999 переходит в NaT)<br>\n",
    "Выбираем те строчки, где EFFECTIVE_TO_DTTM обратилось в NaT, это как раз строчки в которых указана граничная дата, после которой изменялась категория (для этих данных)<br>\n",
    "Далее обнуляем даты, где ACTIVE_FLG==1, это значит что данная категория не поменялась и нам не нужна (еще есть 2 категории которые просто отключили у них  ACTIVE_FLG==0 , но нет маппинга на новую категорию)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opcat_hist['EFFECTIVE_FROM_DTTM']=pd.to_datetime(opcat_hist['EFFECTIVE_FROM_DTTM'],format='%d.%m.%Y')\n",
    "opcat_hist['EFFECTIVE_TO_DTTM']=pd.to_datetime(opcat_hist['EFFECTIVE_TO_DTTM'],  errors='coerce',format='%d.%m.%Y')\n",
    "opcat_hist=opcat_hist[opcat_hist['EFFECTIVE_TO_DTTM'].isnull()].sort_values(by=['OPCAT_ID','EFFECTIVE_FROM_DTTM'])\n",
    "opcat_hist.loc[opcat_hist['ACTIVE_FLG']==1,'EFFECTIVE_FROM_DTTM']=pd.NaT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Достаем столбец дат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opcat_dtm=opcat_hist.sort_values(by='OPCAT_ID')['EFFECTIVE_FROM_DTTM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В маппинге категорий сортируем и добавляем столбец дат <br>\n",
    "Удаляем 1 строчку с 99 категорией<br>\n",
    "Заменяем роли на цифровые значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_opcat_map=opcat_map[['OPCAT_ID_HIST','opcat_id_new','POS_PRIZNAK']].sort_values(by='OPCAT_ID_HIST')\n",
    "new_opcat_map['DATE']=opcat_dtm.values\n",
    "new_opcat_map.drop(new_opcat_map.index[0],inplace=True)\n",
    "new_opcat_map['DATE']=new_opcat_map['DATE'].dt.date\n",
    "new_opcat_map['POS_PRIZNAK']=new_opcat_map['POS_PRIZNAK'].map({'МП':1,'не МП':0})\n",
    "new_opcat_map['POS_PRIZNAK']=new_opcat_map['POS_PRIZNAK'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем словарь для будущего маппинга с категорией, граничной датой и ролью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "role_map={}\n",
    "for row in new_opcat_map.itertuples(index=False):\n",
    "    role_map[row.OPCAT_ID_HIST]=[row.opcat_id_new,row.POS_PRIZNAK,row.DATE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция маппинга для простановки правильных ролей в tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def role_mapping(data,map_dict):\n",
    "    result_arr=np.array([])\n",
    "    for row in data:        \n",
    "        category=row[0]\n",
    "        bound = map_dict[category][2]\n",
    "        new_category=map_dict[category][0]\n",
    "        if pd.isnull(bound):\n",
    "            result_arr=np.append(result_arr,map_dict[category][1])\n",
    "        elif row[1]<bound:\n",
    "            result_arr=np.append(result_arr,map_dict[category][1])\n",
    "        else:\n",
    "            result_arr=np.append(result_arr,map_dict[new_category][1])\n",
    "    return result_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Создаем вспомогательные столбцы <br>\n",
    "Считаем кол-во посетителей в каждый час для каждой категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tickets['EVENT_DTTM']=pd.to_datetime(tickets['EVENT_DTTM'], format=\"%d.%m.%Y %H:%M:%S\")\n",
    "tickets['DATE']=tickets['EVENT_DTTM'].dt.date\n",
    "tickets['HOUR']=tickets['EVENT_DTTM'].dt.hour\n",
    "count_tickets=tickets.groupby(['SUBBRANCH_ID','DATE','HOUR','CURR_OPCAT_ID'])['TICKET_ID'].count()\n",
    "count_tickets=pd.DataFrame({'COUNT':count_tickets}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Достаем даты и категории для получения актуальных ролей <br>\n",
    "Применяем ф-ию маппинга и формируем столбец ROLE<br>\n",
    "Считаем кол-во людей каждый час по каждой роли<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_data=count_tickets[['CURR_OPCAT_ID','DATE']].values\n",
    "count_tickets['ROLE']=role_mapping(np_data,role_map)\n",
    "amount=count_tickets.groupby(['SUBBRANCH_ID','DATE','HOUR','ROLE'])['COUNT'].sum()\n",
    "amount=pd.DataFrame({'AMOUNT':amount}).reset_index()\n",
    "amount['ROLE']=amount['ROLE'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Для целостности данных нужно чтобы каждый час была информация по Обоим ролям, для этого<br>\n",
    "нужно добавить вторую роль там, где получилась только 1 роль для часа<br>\n",
    "Выбираем строчки у которых только 1 роль, удваиваем их (делаем по 1 строчке для каждой роли) и присваиваем 0 кол-во людей<br>\n",
    "Добавляем эту таблицу снизу к основной, удаляем дубли и сортируем<br>\n",
    "В итоге к каждой единичной роли добавилась противоположная с 0 кол-вом людей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "absent_roles=amount.groupby(['SUBBRANCH_ID','DATE','HOUR'])['ROLE'].count()\n",
    "absent_roles=absent_roles[absent_roles==1].reset_index()\n",
    "absent_roles['AMOUNT']=0\n",
    "\n",
    "absent_roles0=absent_roles.copy()\n",
    "absent_roles0['ROLE']=0\n",
    "absent_roles=absent_roles.append(absent_roles0)\n",
    "\n",
    "amount=amount.append(absent_roles)\n",
    "amount=amount.drop_duplicates(['SUBBRANCH_ID','DATE','HOUR','ROLE'])\n",
    "amount=amount.sort_values(by=['SUBBRANCH_ID','DATE','HOUR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Получаем итоговый датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: to_datetime is deprecated. Use pd.to_datetime(...)\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "data_set=amount.copy()\n",
    "data_set.set_index('DATE',inplace=True)\n",
    "data_set.index = data_set.index.to_datetime()\n",
    "data_set['MONTH']=data_set.index.month\n",
    "data_set['DAY']=data_set.index.day\n",
    "data_set['WEEKDAY']=data_set.index.weekday\n",
    "data_set['IS_WEEKEND'] = data_set.WEEKDAY.isin([5,6])*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Меняем стобцы местами, делаем дату индексом и сортируем по дате датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>IS_WEEKEND</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>SUBBRANCH_ID</th>\n",
       "      <th>ROLE</th>\n",
       "      <th>AMOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1005625</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1005625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1005839</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1005839</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1006034</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1006034</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1006255</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1006255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1005625</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1005625</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MONTH  DAY  WEEKDAY  IS_WEEKEND  HOUR  SUBBRANCH_ID  ROLE  AMOUNT\n",
       "2013-07-01      7    1        0           0     8       1005625     0      21\n",
       "2013-07-01      7    1        0           0     8       1005625     1       1\n",
       "2013-07-01      7    1        0           0     8       1005839     0       5\n",
       "2013-07-01      7    1        0           0     8       1005839     1       1\n",
       "2013-07-01      7    1        0           0     8       1006034     0      19\n",
       "2013-07-01      7    1        0           0     8       1006034     1       3\n",
       "2013-07-01      7    1        0           0     8       1006255     0      12\n",
       "2013-07-01      7    1        0           0     8       1006255     1       1\n",
       "2013-07-01      7    1        0           0     9       1005625     0      34\n",
       "2013-07-01      7    1        0           0     9       1005625     1       4"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set=data_set[['MONTH','DAY','WEEKDAY','IS_WEEKEND','HOUR','SUBBRANCH_ID','ROLE','AMOUNT']]\n",
    "data_set['date']=data_set.index\n",
    "data_set=data_set.sort_values(by=['date','HOUR']).drop(['date'],axis=1)\n",
    "data_set.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем на обучающую и валидационную выборки и выделяем целевую переменную y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size=0.3\n",
    "test_index=int(len(data_set)*(1-test_size))\n",
    "train=data_set[:test_index]\n",
    "y_train=train['AMOUNT']\n",
    "X_train=train.drop(['AMOUNT'],axis=1)\n",
    "test=data_set[test_index:]\n",
    "y_test=test['AMOUNT']\n",
    "X_test=test.drop(['AMOUNT'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавляем фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Пробовал вводить разбиения по дням\n",
    "'''def some_days(x):\n",
    "    if x <11:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "        \n",
    "X_train['SOMEDAYS']=X_train['DAY'].apply(some_days)'''\n",
    "\n",
    "# И по сезонам  \n",
    "'''def season(x):\n",
    "      return (x-1)//3\n",
    "      \n",
    "X_train['SEASON']=X_train['MONTH'].apply(season)'''\n",
    "\n",
    "# Но результата не принесло"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>IS_WEEKEND</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>SUBBRANCH_ID</th>\n",
       "      <th>ROLE</th>\n",
       "      <th>HOUR_SUBBRANCH_ID</th>\n",
       "      <th>ROLE_SUBBRANCH_ID</th>\n",
       "      <th>HOUR_ROLE</th>\n",
       "      <th>WEEKDAY_HOUR</th>\n",
       "      <th>WEEKDAY_SUBBRANCH_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1005625</td>\n",
       "      <td>0</td>\n",
       "      <td>8_1005625</td>\n",
       "      <td>0_1005625</td>\n",
       "      <td>8_0</td>\n",
       "      <td>0_8</td>\n",
       "      <td>0_1005625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1005625</td>\n",
       "      <td>1</td>\n",
       "      <td>8_1005625</td>\n",
       "      <td>1_1005625</td>\n",
       "      <td>8_1</td>\n",
       "      <td>0_8</td>\n",
       "      <td>0_1005625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1005839</td>\n",
       "      <td>0</td>\n",
       "      <td>8_1005839</td>\n",
       "      <td>0_1005839</td>\n",
       "      <td>8_0</td>\n",
       "      <td>0_8</td>\n",
       "      <td>0_1005839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1005839</td>\n",
       "      <td>1</td>\n",
       "      <td>8_1005839</td>\n",
       "      <td>1_1005839</td>\n",
       "      <td>8_1</td>\n",
       "      <td>0_8</td>\n",
       "      <td>0_1005839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1006034</td>\n",
       "      <td>0</td>\n",
       "      <td>8_1006034</td>\n",
       "      <td>0_1006034</td>\n",
       "      <td>8_0</td>\n",
       "      <td>0_8</td>\n",
       "      <td>0_1006034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MONTH  DAY  WEEKDAY  IS_WEEKEND  HOUR  SUBBRANCH_ID  ROLE  \\\n",
       "2013-07-01      7    1        0           0     8       1005625     0   \n",
       "2013-07-01      7    1        0           0     8       1005625     1   \n",
       "2013-07-01      7    1        0           0     8       1005839     0   \n",
       "2013-07-01      7    1        0           0     8       1005839     1   \n",
       "2013-07-01      7    1        0           0     8       1006034     0   \n",
       "\n",
       "           HOUR_SUBBRANCH_ID ROLE_SUBBRANCH_ID HOUR_ROLE WEEKDAY_HOUR  \\\n",
       "2013-07-01         8_1005625         0_1005625       8_0          0_8   \n",
       "2013-07-01         8_1005625         1_1005625       8_1          0_8   \n",
       "2013-07-01         8_1005839         0_1005839       8_0          0_8   \n",
       "2013-07-01         8_1005839         1_1005839       8_1          0_8   \n",
       "2013-07-01         8_1006034         0_1006034       8_0          0_8   \n",
       "\n",
       "           WEEKDAY_SUBBRANCH_ID  \n",
       "2013-07-01            0_1005625  \n",
       "2013-07-01            0_1005625  \n",
       "2013-07-01            0_1005839  \n",
       "2013-07-01            0_1005839  \n",
       "2013-07-01            0_1006034  "
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пробовал делать пересечения признаков (результат бустинга ухудшился, лин. регрессии немного улучшился)\n",
    "'''categ_features = X_train.columns[X_train.dtypes == 'category']\n",
    "for i, col1 in enumerate(categ_features):\n",
    "    for j, col2 in enumerate(categ_features[i + 1:]):\n",
    "        X_train[col1 + '_' + col2] = X_train[col1].astype(str) + '_' + X_train[col2].astype(str) \n",
    "        X_test[col1 + '_' + col2] = X_test[col1].astype(str) + '_' + X_test[col2].astype(str) '''\n",
    "\n",
    "X_train_lin=X_train.copy()\n",
    "X_test_lin=X_test.copy()\n",
    "\n",
    "# Для лин. регрессии эти пересечения признаков улучшили результат        \n",
    "second_col=['SUBBRANCH_ID','SUBBRANCH_ID','ROLE','HOUR','SUBBRANCH_ID']\n",
    "for i, col1 in enumerate(['HOUR','ROLE','HOUR','WEEKDAY','WEEKDAY']):\n",
    "    col2 = second_col[i]\n",
    "    X_train_lin[col1 + '_' + col2] = X_train_lin[col1].astype(str) + '_' + X_train_lin[col2].astype(str) \n",
    "    X_test_lin[col1 + '_' + col2] = X_test_lin[col1].astype(str) + '_' + X_test_lin[col2].astype(str)\n",
    "    \n",
    "X_train_lin.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем столбцы категориальными (для бустингов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in X_train.columns:\n",
    "    X_train[col]=X_train[col].astype('category')\n",
    "for col in X_test.columns:\n",
    "    X_test[col]=X_test[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейные регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr=LinearRegression()\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "lscv=LassoCV(cv=tscv, n_jobs=-1, random_state=17)\n",
    "rcv=Ridge(alpha=10)\n",
    "ohe=OneHotEncoder(dtype=np.int,categorical_features='all')\n",
    "pf=PolynomialFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Пhобовал добавлять полиноминальные признаки, но они не дали почти прироста\n",
    "'''pf_fit=pf.fit(X_train)\n",
    "X_train=pf_fit.transform(X_train)\n",
    "X_test=pf_fit.transform(X_test)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаю one hot encoding для категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_ohe=ohe.fit(X_train_lin)\n",
    "X_o_train=fit_ohe.transform(X_train_lin)\n",
    "X_o_test=fit_ohe.transform(X_test_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55605, 287)"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_o_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge регрессия "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rcv.fit(X_o_train,y_train)\n",
    "y_pred_rcv=rcv.predict(X_o_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 = 0.787582\n",
      "MAE = 5.594226\n"
     ]
    }
   ],
   "source": [
    "y_pred_rcv=np.around(y_pred_rcv)\n",
    "print('r2 = %f' % (r2_score(y_test, y_pred_rcv)))\n",
    "print('MAE = %f' % (mean_absolute_error(y_test, y_pred_rcv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svr=SVR()\n",
    "svr.fit(X_o_train,y_train)\n",
    "y_pred_svr=svr.predict(X_o_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 = 0.794316\n",
      "MAE = 5.334145\n"
     ]
    }
   ],
   "source": [
    "y_pred_svr=np.around(y_pred_svr)\n",
    "print('r2 = %f' % (r2_score(y_test, y_pred_svr)))\n",
    "print('MAE = %f' % (mean_absolute_error(y_test, y_pred_svr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбирал параметры с помощью GridSearchCV, самую успешную комбинацию для cat_features подбирал руками <br>\n",
    "Улучшения и дополнительные признаки не помогли результату catboost, самый лучший результат получился на начальном датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tree_params={'l2_leaf_reg':[3,4,5,6,7]}\n",
    "#dt_grid_search = GridSearchCV(cat, tree_params, n_jobs=-1, scoring ='neg_mean_squared_error', cv=tscv)\n",
    "#dt_grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat=CatBoostRegressor(iterations=500, \n",
    "    random_seed=17 ,loss_function='RMSE',depth=8,learning_rate=0.01,random_strength=1,l2_leaf_reg = 6 , one_hot_max_size=1 ,\n",
    "                       verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x14833109898>"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.fit(X_train, y_train,use_best_model=True,  \n",
    "cat_features=list([4,5]),\n",
    "        eval_set=(X_test, y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=cat.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат на отложенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 = 0.838756\n",
      "MAE = 4.590240\n"
     ]
    }
   ],
   "source": [
    "y_pred=np.around(y_pred)\n",
    "print('r2 = %f' % (r2_score(y_test, y_pred)))\n",
    "print('MAE = %f' % (mean_absolute_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1871125164392382,\n",
       " 2.931933737860773,\n",
       " 1.7585678997286018,\n",
       " 0.6752033639746216,\n",
       " 11.698305459349323,\n",
       " 7.025792754213112,\n",
       " 74.72308426843432]"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат на кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.3112450285687745"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1*np.mean(cross_val_score(cat, X_train, y_train, cv=tscv, scoring='neg_mean_absolute_error'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использовал LGBM для дополнительной проверки результатов, и для быстрой проверки новых признаков <br>\n",
    "LGBM отработал хуже чем catboost, зато намного быстрее выполняется обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LGBM работает только с числовыми данными, поэтому приходилось перекодировать признаки в процессе тестирования\n",
    "'''le=LabelEncoder()\n",
    "for i in X_train.columns[9:]:\n",
    "    X_train[i]=le.fit_transform(X_train[i])\n",
    "for i in X_test.columns[9:]:\n",
    "    X_test[i]=le.fit_transform(X_test[i])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train=lgb.Dataset(X_train,label=y_train)\n",
    "L_test=lgb.Dataset(X_test,label=y_test)\n",
    "lgbparam                 = {}\n",
    "lgbparam['metric']       = 'rmse'\n",
    "lgbparam['application']  = 'regression'\n",
    "lgbparam['nthread']      = 6\n",
    "lgbparam['num_boost_round']=1000\n",
    "lgbparam['max_depth']=5\n",
    "#lgbparam['max_cat_to_onehot'] = 2\n",
    "#lgbparam['learning_rate'] = 0.05\n",
    "#lgbparam['boosting']         = 'rf'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1 rounds.\n",
      "[10]\tvalid_0's rmse: 8.83993\n",
      "[20]\tvalid_0's rmse: 7.35374\n",
      "[30]\tvalid_0's rmse: 7.21964\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's rmse: 7.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:99: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:681: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    }
   ],
   "source": [
    "lgb_model = lgb.train(lgbparam, L_train,valid_sets=[L_test], verbose_eval=10,early_stopping_rounds=1)\n",
    "lgb_pred=lgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат на отложенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 = 0.815824\n",
      "MAE = 5.192606\n"
     ]
    }
   ],
   "source": [
    "lgb_pred=np.around(lgb_pred)\n",
    "print('r2 = %f' % (r2_score(y_test, lgb_pred)))\n",
    "print('MAE = %f' % (mean_absolute_error(y_test, lgb_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему-то lgbm совсем по другому расставил важность признакам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ROLE', 29),\n",
       " ('WEEKDAY', 62),\n",
       " ('IS_WEEKEND', 84),\n",
       " ('MONTH', 135),\n",
       " ('SUBBRANCH_ID', 161),\n",
       " ('HOUR', 175),\n",
       " ('DAY', 179)]"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(zip(X_train.columns,lgb_model.feature_importance())),key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат на кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:681: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 678 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv_scores = []\n",
    "for train_idx, test_idx in tscv.split(X_train, y_train):\n",
    "    cv_train_df, cv_valid_df = X_train.iloc[train_idx, :], X_train.iloc[test_idx, :]\n",
    "    y_cv_train, y_cv_valid = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    L_train=lgb.Dataset(cv_train_df,label=y_cv_train)\n",
    "    lgb_model = lgb.train(lgbparam, L_train)\n",
    "    \n",
    "    cv_scores.append(mean_absolute_error(y_cv_valid, lgb_model.predict(cv_valid_df,num_iteration =-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.263305042686472"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "В итоге лучшей моделью оказался catboost в данной задаче <br>\n",
    "Приминения различных методов работы с признаками, к сожалению, не дали ощутимого результата <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
